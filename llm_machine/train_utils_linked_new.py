# vt_siglip/train_utils_linked.py
import torch
from .siglip_model import VisionTextSigLIP
from .data_linked import ImageBatchMulti, TextBatchSingle, build_targets_imgmulti_textsingle


# ===================== #
#  train_step_linked    #
# ===================== #

def train_step_linked(
    vt: VisionTextSigLIP,
    token_model,                      # âœ… ì™¸ë¶€ Token ëª¨ë¸ (freeze ìƒíƒœ)
    batch_img: ImageBatchMulti,
    batch_txt: TextBatchSingle,
    optimizer: torch.optim.Optimizer,
    scaler: torch.cuda.amp.GradScaler | None = None,
    amp_dtype: torch.dtype = torch.bfloat16,
) -> dict:
    """
    ì´ë¯¸ì§€ â†’ Token.forward_test â†’ image_feats
    image_feats + í…ìŠ¤íŠ¸(batch_txt)ë¥¼ vtì— ë„£ì–´ì„œ
    vt ë‚´ë¶€ì˜ contrastive(v, h_attn) lossë¡œ í•™ìŠµí•˜ëŠ” í•œ ìŠ¤í….
    """
    vt.train()
    device = next(vt.parameters()).device
    use_amp = (device.type == "cuda")

    # 1) ë°°ì¹˜ í…ì„œ ë””ë°”ì´ìŠ¤ ì´ë™
    if hasattr(batch_img, "images"):
        images = batch_img.images.to(device, non_blocking=True)
    elif isinstance(batch_img, dict) and "images" in batch_img:
        images = batch_img["images"].to(device, non_blocking=True)
    else:
        raise TypeError("batch_imgì—ì„œ images í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤.")

    input_ids = batch_txt.input_ids.to(device, non_blocking=True)
    attention_mask = batch_txt.attention_mask.to(device, non_blocking=True)

    optimizer.zero_grad(set_to_none=True)

    # 2) AMP context
    ctx = torch.autocast("cuda", dtype=amp_dtype, enabled=use_amp)
    with ctx:
        # Tokenì€ freeze ìƒíƒœì´ë¯€ë¡œ grad ë¶ˆí•„ìš”
        with torch.no_grad():
            global_vector, token_num = token_model.forward_test(images)  # (B, Dv)
        targets = build_targets_imgmulti_textsingle(batch_img.label_sets, batch_txt.labels).to(device)


        # ğŸ”¥ vt.forward ê°€ v / h_attn / contrastive loss ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•œë‹¤ê³  ê°€ì •
        out = vt(
            image_feats=token_num,
            text_input_ids=input_ids,
            text_attention_mask=attention_mask,
            targets=targets,
            return_embeddings=False,
        )

        loss = out["loss"]

    # 3) backward + optimizer step
    if scaler is not None and use_amp:

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
    else:
        loss.backward()
        optimizer.step()

    logs = {
        "loss": float(loss.detach().cpu().item()),
        "temp": float(out.get("temp", 0.0)),
    }
    return logs
